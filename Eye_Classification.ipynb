{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d953byVfwLQl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage import io\n",
    "\n",
    "local = True\n",
    "show_images = False\n",
    "\n",
    "sF_steps = 100\n",
    "sF_start = 1.5\n",
    "sF_end = 8\n",
    "\n",
    "mN_start = 1\n",
    "mN_end = 10\n",
    "\n",
    "imgs = {}\n",
    "img_dir = \"images\"\n",
    "\n",
    "if(local):\n",
    "    img_files = [f for f in os.listdir(img_dir) if not f.startswith(\".\")]\n",
    "    imgs = [cv2.imread(os.path.join(img_dir, f)) for f in img_files if not f.startswith(\".\")]\n",
    "    imgs = dict(zip(img_files, imgs))\n",
    "else:\n",
    "    base_url = \"https://github.com/dan91/haarClassifierParameterAnalysis/raw/master/\"\n",
    "    img_url = os.path.join(base_url, \"images\")\n",
    "    amount_images = 8\n",
    "    for i in tqdm(range(1, amount_images + 1)):\n",
    "        fN = str(i)+\".png\"\n",
    "        imgs.update({(fN): io.imread(os.path.join(img_url, fN)) } )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y48bBRew-kHe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import urllib.request\n",
    "if(local):\n",
    "    with open('labels.json') as f:\n",
    "        labels = json.load(f)\n",
    "else:\n",
    "    labels = json.load(urllib.request.urlopen(os.path.join(base_url, \"labels.json\")))\n",
    "    \n",
    "ids = [d['External ID'] for d in labels if d['Label'] != 'Skip']\n",
    "coords = [d['Label']['Eye'][0]['geometry'] for d in labels if d['Label'] != 'Skip']\n",
    "labels = dict(zip(ids,coords))\n",
    "\n",
    "file_name = \"haarcascade_eye.xml\"\n",
    "if(not local):\n",
    "    urllib.request.urlretrieve(\"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_eye.xml\", file_name)\n",
    "cascade = cv2.CascadeClassifier(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s3KUTUhaIsCy"
   },
   "outputs": [],
   "source": [
    "# https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/visualize.py\n",
    "def display_images(images, cols):\n",
    "    rows = len(images) // cols + 1\n",
    "    plt.figure(figsize=(14, 14 * rows // cols))\n",
    "    i = 1\n",
    "    for image in images:\n",
    "        plt.subplot(rows, cols, i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image.astype(np.uint8))\n",
    "        i += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "count_total = 0\n",
    "images_after_drawings = []\n",
    "res = {}\n",
    "def detect_objects(sF, mN):\n",
    "    start_time = time.time()\n",
    "    count_true_pos = count_true_neg = count_false_pos = count_false_neg = 0\n",
    "    count_image_batch = 1\n",
    "    for img in imgs:\n",
    "        current_img = imgs[img].copy()\n",
    "\n",
    "        (rects, weights, levels) = cascade.detectMultiScale3(imgs[img], scaleFactor=sF, minNeighbors = mN, flags=cv2.CASCADE_SCALE_IMAGE, outputRejectLevels = True\n",
    "        )\n",
    "        ground_truth_object = False\n",
    "        detected_object = False\n",
    "        detected_object_correct_position = False\n",
    "\n",
    "        # this is needed to show a green/red cirlce in upper left corner if there is no ground truth object \n",
    "        x_t = y_t = 5\n",
    "        # image contains object\n",
    "        if(img in labels):\n",
    "            ground_truth_object = True\n",
    "            x_t = labels[img]['x']\n",
    "            y_t = labels[img]['y']\n",
    "\n",
    "        # if openCV doesn't detect any objects, rects is a tuple (not a np array) and we skip it   \n",
    "        if(type(rects) is np.ndarray):\n",
    "            detected_object = True\n",
    "            # we only look at the object with the highest weight         \n",
    "            heighest_weight = (weights.tolist().index(max(weights)))\n",
    "            rect = rects[heighest_weight]\n",
    "            x1, y1, x2, y2 = rect\n",
    "            cv2.rectangle(current_img, (x1, y1), (x2, y2), (255,255,255,255), 5)\n",
    "\n",
    "            if(ground_truth_object):\n",
    "                # check if ground truth object is within detected object \n",
    "                if((x_t > x1 and x_t < x2) and (y_t > y1 and y_t < y2)):\n",
    "                    detected_object_correct_position = True\n",
    "\n",
    "        # here we determine the outcome of the prediction and print a colored ground truth circle \n",
    "        # (or a circle in the upper left corner if no ground truth object present)\n",
    "        # (green = true, red = false).\n",
    "        if(ground_truth_object and detected_object_correct_position):\n",
    "            count_true_pos += 1\n",
    "            c = (0, 255, 0, 255)\n",
    "        elif(ground_truth_object and not detected_object):\n",
    "            count_false_neg += 1\n",
    "            c = (255, 0, 0, 255)\n",
    "        elif(ground_truth_object and not detected_object_correct_position):\n",
    "            count_false_pos += 1\n",
    "            c = (255, 0, 0, 255)\n",
    "        elif(not ground_truth_object and detected_object):\n",
    "            count_false_pos += 1\n",
    "            c = (255, 0, 0, 255)\n",
    "        elif(not ground_truth_object and not detected_object):\n",
    "            count_true_neg += 1\n",
    "            c = (0, 255, 0, 255)\n",
    "\n",
    "        cv2.circle(current_img, (x_t, y_t), 3, c, 20)\n",
    "        images_after_drawings.append(current_img)\n",
    "\n",
    "    res.update({(sF,mN): { \n",
    "        \"duration\": (time.time() - start_time)/len(imgs), \n",
    "        \"f1\": (2*count_true_pos)/(2*count_true_pos+count_false_pos+count_false_neg)}}\n",
    "    )\n",
    "    if(show_images):\n",
    "        print(\" --- scaleFactor: {}, minNeightbors: {}\".format(sF, mN))\n",
    "        display_images(images_after_drawings[-8:], cols=len(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dcvRdm_kjPYn",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sF in tqdm(np.linspace(sF_start, sF_end, sF_steps)):\n",
    "    for mN in range(mN_start, mN_end):\n",
    "        detect_objects(sF, mN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OEx7QzK0E-E9"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/47230966\n",
    "def configure_plotly_browser_state():\n",
    "    import IPython\n",
    "    display(IPython.core.display.HTML('''\n",
    "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
    "        <script>\n",
    "          requirejs.config({\n",
    "            paths: {\n",
    "              base: '/static/base',\n",
    "              plotly: 'https://cdn.plot.ly/plotly-1.5.1.min.js?noext',\n",
    "            },\n",
    "          });\n",
    "        </script>\n",
    "        '''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hnuUr5EsyWUj"
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "configure_plotly_browser_state()\n",
    "\n",
    "init_notebook_mode(connected=False)\n",
    "\n",
    "t = [v['duration'] for v in res.values()]\n",
    "a = [v['f1'] for v in res.values()]\n",
    "text = [str(k) for k in res.keys()]\n",
    "# Create a trace\n",
    "trace = go.Scatter(\n",
    "    x = t,\n",
    "    y = a,\n",
    "    mode = 'markers',\n",
    "    text = text,\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "layout = go.Layout(\n",
    "    yaxis=dict(\n",
    "        range=[0, 1]\n",
    "    )\n",
    ")\n",
    "\n",
    "       \n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, filename='basic-line.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Eye Classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
